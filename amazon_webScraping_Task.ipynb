{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the essential packages \n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  a.)  Text input to use to search Amazon "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# b.)  The key data returned by the API into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "params = {\n",
    "    'api_key': '0F5DAC23BEB543C1B26A6CD61B44A5E9',\n",
    "    'type': 'category',\n",
    "    'url': 'https://www.amazon.com/s?bbn=16225009011&rh=n%3A%2116225009011%2Cn%3A502394%2Cn%3A281052',\n",
    "    'page': '1'\n",
    "    }\n",
    "  # make the http GET request to Rainforest API\n",
    "api_result = requests.get('https://api.rainforestapi.com/request', params)\n",
    "api_response = api_result.json()\n",
    "data1 = pd.DataFrame(api_response['category_results'])\n",
    "\n",
    "  \n",
    "for x in range(1,11):\n",
    "    params = {\n",
    "    'api_key': 'F1C8601D5CC5445EB858CC86A4F6DBF8',\n",
    "    'type': 'category',\n",
    "    'url': 'https://www.amazon.com/s?bbn=16225009011&rh=n%3A%2116225009011%2Cn%3A502394%2Cn%3A281052',\n",
    "    'page': x\n",
    "    }\n",
    "   # make the http GET request to Rainforest API\n",
    "  #print(x)\n",
    "    api_result = requests.get('https://api.rainforestapi.com/request', params)\n",
    "    api_response = api_result.json()\n",
    "  \n",
    "  # Read the file in to dataframe\n",
    "  \n",
    "    data = pd.DataFrame(api_response['category_results'])\n",
    "    data1 = data1.append(data,ignore_index=True)\n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above chunck of code, Rainforest API has been called to search amazon product called digital cameras. In the above code, 10 pages was fetched on Amazon using rainforest API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the shape of the dataframe\n",
    "data1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Display the first few rows of the dataframe\n",
    "data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the basic information about the variable in the dataframe\n",
    "data1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 312 obsevations and 18 columns in the dataframe. Product name, Product image url and Price are the important variables for futher task for this project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove non-Amazon prime products "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the data which is not Amazon prime\n",
    "data2 = data1.loc[data1['is_prime'] == True]\n",
    "data2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre- process the price column to get price \n",
    "df3 = data2['price'].apply(pd.Series)\n",
    "df3.head()\n",
    "df3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the two dataframe \n",
    "merged_data = pd.merge(data2, df3, left_index=True, right_index=True)\n",
    "merged_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reanme the value column into price_item\n",
    "\n",
    "merged_data.rename({'value': 'price_item'}, axis=1, inplace=True)\n",
    "merged_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sort the rest by price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the dataframe by price_item\n",
    "\n",
    "merged_data1 = merged_data.sort_values(by='price_item')\n",
    "merged_data1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the dataframe as a csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data1.to_csv('Amazon_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the product image for each product in the dataframe using the image url and save as a jpg to a local folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product = pd.read_csv('A.csv')\n",
    "urls1 = product['image']\n",
    "urls1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the directory\n",
    "os.chdir('C:\\\\Users\\\\01-18-20\\\\Documents\\\\Job_Applications\\\\CV_New\\\\NHS\\\\image_folder')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "for img in urls1:\n",
    "    # We can split the file based upon / and extract the last split within the python list below:\n",
    "    file_name = img.split('/')[-1]\n",
    "    \n",
    "    print(f\"This is the file name: {file_name}\")\n",
    "    # Now let's send a request to the image URL:\n",
    "    r = requests.get(img, stream=True)\n",
    "    # We can check that the status code is 200 before doing anything else:\n",
    "    if r.status_code == 200:\n",
    "        # This command below will allow us to write the data to a file as binary:\n",
    "        with open(file_name, 'wb') as f:\n",
    "            for chunk in r:\n",
    "                f.write(chunk)\n",
    "    else:\n",
    "        # We will write all of the images back to the broken_images list:\n",
    "        images.append(img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the images are stored in the local folder called image_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # Combine several products into one combined image montage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"C:\\\\Users\\\\01-18-20\\\\Documents\\\\Job_Applications\\\\CV_New\\\\NHS\\\\image_folder\")\n",
    "image_paths = [os.path.abspath(i) for i in os.listdir()]\n",
    "print(image_paths)\n",
    "\n",
    "#print(f\"{len(image_paths)} image(s) found!\")\n",
    "rows = int(input(\"Enter the number of rows: \"))\n",
    "columns = int(input(\"Enter the number of columns: \"))        \n",
    "size = 300\n",
    "for image_path in image_paths:\n",
    "    image = cv2.imread(image_path)\n",
    "    image_size = image.shape[0]\n",
    "    if image_size <size:\n",
    "        size = image_size\n",
    "counter = 0\n",
    "image_rows = []\n",
    "for row in range(rows):\n",
    "    for column in range(columns):\n",
    "        image = cv2.imread(image_paths[counter])\n",
    "        image = cv2.resize(image,(size, size))\n",
    "        if column == 0:\n",
    "            image_list = image\n",
    "        else:\n",
    "            image_list = np.concatenate((image_list, image), axis = 1)\n",
    "        counter += 1     \n",
    "    image_rows.append(image_list)\n",
    "montage = np.concatenate(image_rows, axis=0)\n",
    "      \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the montage image\n",
    "# cv2.imwrite(\"montage_test2.jpg\", montage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some images metrics such as brightness/contrast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load  the image\n",
    "image_bright = cv2.imread(\"C:\\\\Users\\\\01-18-20\\\\Documents\\\\Job_Applications\\\\CV_New\\\\NHS\\\\image_folder\\\\51JSQ8NaX3L._AC_UL320_.jpg\")\n",
    "cv2.imshow(\"Original\",image_bright)\n",
    "\n",
    "# Matrix of ones which is multiplied by a scaler value of 60\n",
    "intensity_matrix = np.ones(image_bright.shape, dtype = \"uint8\")*60\n",
    "\n",
    "# Add intensity matrix to input image in order to increase the brightness\n",
    "brighted_image = cv2.add(image_bright, intensity_matrix)\n",
    "cv2.imshow(\"Bright\", brighted_image)\n",
    "\n",
    "# Subtract intensity matrix from input image in order to decrease the brightness\n",
    "drakened_image = cv2.subtract(image_bright, intensity_matrix)\n",
    "cv2.imshow(\"Dark\", drakened_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the images\n",
    "cv2.imwrite(\"bright_test.jpg\", brighted_image)\n",
    "cv2.imwrite(\"drakened_test.jpg\", drakened_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
